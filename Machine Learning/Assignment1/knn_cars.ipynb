{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: K-Nearest Neighbor (10 marks)\n",
    "\n",
    "Student Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "## General info\n",
    "\n",
    "<b>Due date</b>: Friday, 12 August 2022 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -10% per day up to 5 days (both weekdays and weekends count). Submissions more than 5 days late will not be accepted (resul in a mark of 0).\n",
    "<ul>\n",
    "    <li>one day late, -1.0;</li>\n",
    "    <li>two days late, -2.0;</li>\n",
    "    <li>three days late, -3.0;</li>\n",
    "    <li>four days late, -4.0;</li>\n",
    "    <li>five days late, -5.0;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Extensions</b>: Students who are demonstrably unable to submit a full solution in time due to medical reasons or other trauma, may apply for an extension.  In these cases, you should email <a href=\"mailto:hasti.samadi@unimelb.edu.au\">Hasti Samadi</a> as soon as possible after those circumstances arise. If you attend a GP or other health care service as a result of illness, be sure to provide a Health Professional Report (HPR) form (get it from the Special Consideration section of the Student Portal), you will need this form to be filled out if your illness develops into something that later requires a Special Consideration application to be lodged. You should scan the HPR form and send it with the extension requests.\n",
    "\n",
    "<b>Marks</b>: This assignment will be marked out of 10, and make up 10% of your overall mark for this subject.\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/126693/pages/python-and-jupyter-notebooks?module_item_id=3950453) on Canvas (under Modules> Coding Resources) for information on the basic setup required for this class, including an iPython notebook viewer.If your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (Piazza -> Assignments -> A1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: While you may discuss this homework in general terms with other students, it ultimately is still an individual task. Reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/126693/modules#module_734188\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions: \n",
    "<UL TYPE=”square”>\n",
    "<LI>missing Authorship Declaration at the bottom of the page, -5.0\n",
    "<LI>incomplete or unsigned Authorship Declaration at the bottom of the page, -3.0\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this homework, you'll be applying the K-nearest neighbor (KNN) classification algorithm to a real-world machine learning data set. In particular, we will predict the affordability of a car given a diverse set of features, including the make, engine type, style,  and horsepower and other descriptive properties of the car.\n",
    "\n",
    "Firstly, you will read in the dataset into a train and a test set, and you will create two feature sets (Q1). Secondly, you will implement different distance functions (Q2). Thirdly, you will implement one KNN classifier (Q3, Q4) and apply it to the data set using different distance functions and parameter K (Q5). Finally, you will assess the quality of your classifier by comparing its class predictions to the gold standard labels (Q6).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Loading the data (0.5 marks)\n",
    "\n",
    "**Instructions:** For this assignment we will develop a K-Nearest Neighbors (KNN) classifier to predict the \n",
    "affordability of cars. The list of classes is:\n",
    "\n",
    "```\n",
    "cheap\n",
    "affordable\n",
    "expensive\n",
    "very expensive\n",
    "```\n",
    "\n",
    "We use a modified version of the Car data set from the UCI Machine learning repository.\n",
    "\n",
    "The original data can be found here: https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "\n",
    "The dataset consists of 204 instances. Each instance corresponds to a car which has a unique identifier (X; first field) and is characterized with 24 features as described in the file *car.names* which is provided as part of this assignment.\n",
    "\n",
    "You need to first obtain this dataset, which is on Canvas (assignment 1). The files *car.features* and *car.labels* contain the data we will use in this notebook. Make sure the files are saved in the same folder as this notebook. \n",
    "\n",
    "Both files are in comma-separated value format. The first line in each file is a header, naming each feature (or label).\n",
    "\n",
    "*car.features* contains 204 instances, one line per instance. The first field is the unique instance identifier. The following fields contain the 24 features, as described in the file *car.names*.\n",
    "\n",
    "*car.labels* contains the gold labels (i.e., one of the four classes above), one instance per line. Again, the first field is the instance identifier, and the second field the instance label.\n",
    "\n",
    "*car.names* contains additional explanations about the data set and the features.\n",
    "\n",
    "All feature values are floats, and for Questions 1 through 5, we make the simplifying assumption that all values are indeed real-valued. You may want to revisit this assumption in Question 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Task**: Read the two files  \n",
    "1. create a **training_feature** set (list of features for the first 163 instances in the car.* files) and a **training_label** set (list of labels for the corresponding). \n",
    "2. create a **test_feature** set (list of features of the remaining instances in the car.* files) and a **test_label** set (list of labels for the corresponding). \n",
    "---------\n",
    "- Do **not** shuffle the data.\n",
    "- Do **not** modify feature or label representations. \n",
    "- Features must be represented as floats.\n",
    "--------\n",
    "You may use any Python packages you want, but not change the specified data types (i.e., they should be of type List, and *not* dataframe, dictionary etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0,2,20,1,0,1,2,3,0,98.4,176.2,0.45299145299145266,52.0,0.46198603568657876,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '1,0,19,1,0,0,5,2,0,97.0,173.5,0.4358974358974365,53.0,0.3110938712179985,4,3,0.17735849056603772,2,3.62,2.64,9.0,0.1588785046728972,4800.0,28,32\\n', '2,0,3,1,0,0,4,3,0,110.0,197.0,0.9059829059829065,56.3,0.7823894491854151,3,4,0.5584905660377358,6,3.62,3.39,8.0,0.6261682242990654,5400.0,15,20\\n', '3,2,21,1,0,0,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.30527540729247477,3,3,0.1811320754716981,6,3.19,3.4,9.0,0.17289719626168223,5250.0,27,34\\n', '4,0,14,0,1,0,5,3,0,114.2,198.9,0.6923076923076928,58.7,0.7532971295577967,2,3,0.3433962264150943,4,3.7,3.52,21.0,0.21962616822429906,4150.0,25,25\\n', '5,-1,22,0,1,0,4,3,0,109.1,188.8,0.7350427350427355,55.5,0.6706749418153607,3,4,0.3169811320754717,4,3.01,3.4,23.0,0.27102803738317754,4800.0,26,27\\n', '6,-1,10,0,1,0,4,3,0,110.0,190.9,0.8547008547008544,56.5,0.7862684251357641,3,2,0.46037735849056605,4,3.58,3.64,21.5,0.35046728971962615,4350.0,22,25\\n', '7,-1,22,1,0,0,4,3,0,109.1,188.8,0.7350427350427355,55.5,0.5678820791311094,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,23,28\\n', '8,3,13,1,1,1,3,3,0,91.3,170.7,0.6495726495726502,49.7,0.6404189294026377,5,4,0.4528301886792453,6,3.43,3.27,7.8,0.7102803738317757,5200.0,17,23\\n', '9,0,9,0,0,0,4,3,0,104.9,175.0,0.49572649572649535,54.4,0.47013188518231186,3,3,0.27547169811320754,4,3.43,3.64,22.0,0.11214953271028037,4200.0,31,39\\n', '10,2,12,1,0,1,3,2,0,93.7,157.3,0.35042735042735107,50.8,0.20015515903801395,3,3,0.1169811320754717,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '11,1,13,1,0,1,3,3,0,99.2,178.5,0.6495726495726502,49.7,0.6404189294026377,5,4,0.4528301886792453,6,3.43,3.27,9.0,0.5233644859813084,5200.0,19,25\\n', '12,0,14,0,1,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.6842513576415826,2,3,0.3433962264150943,4,3.7,3.52,21.0,0.21962616822429906,4150.0,28,33\\n', '13,1,5,1,1,0,4,2,0,93.7,157.3,0.2991452991452991,50.6,0.2726920093095423,3,3,0.13962264150943396,6,3.03,3.39,7.6,0.2523364485981308,5500.0,24,30\\n', '14,0,8,1,0,1,4,3,0,102.0,191.7,0.8803418803418799,47.8,0.9550038789759504,5,6,1.0,6,3.54,2.76,11.5,1.0,5000.0,13,17\\n', '15,2,18,1,0,0,4,2,0,99.1,186.6,0.52991452991453,56.1,0.4926299456943367,3,3,0.22641509433962265,6,3.54,3.07,9.3,0.2897196261682243,5250.0,21,28\\n', '16,0,20,1,0,0,4,2,0,95.7,166.3,0.35042735042735107,53.0,0.23506594259115593,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,38,47\\n', '17,3,20,1,0,1,3,3,0,102.9,183.5,0.6324786324786328,52.0,0.5927075252133437,1,4,0.41509433962264153,6,3.27,3.35,9.3,0.5280373831775701,5200.0,19,24\\n', '18,2,20,1,0,1,2,3,0,98.4,176.2,0.45299145299145266,52.0,0.40806826997672613,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '19,3,1,1,0,1,1,3,0,88.6,168.8,0.32478632478632447,48.8,0.41117145073700545,1,3,0.26037735849056604,6,3.47,2.68,9.0,0.29439252336448596,5000.0,21,27\\n', '20,1,6,1,0,1,3,2,0,93.7,150.0,0.3162393162393164,52.6,0.18153607447633824,3,3,0.1169811320754717,1,2.91,3.41,9.2,0.1308411214953271,6000.0,30,34\\n', '21,2,19,1,0,1,3,2,0,93.7,156.9,0.264957264957265,53.7,0.21799844840961985,4,3,0.13584905660377358,2,3.62,2.36,9.0,0.09813084112149532,4900.0,31,36\\n', '22,-1,10,0,1,0,5,3,0,110.0,190.9,0.8547008547008544,58.7,0.8774243599689682,3,2,0.46037735849056605,4,3.58,3.64,21.5,0.35046728971962615,4350.0,22,25\\n', '23,3,21,1,0,1,3,2,0,94.5,165.7,0.3162393162393164,51.4,0.2843289371605896,3,3,0.1811320754716981,6,3.19,3.4,8.5,0.19626168224299065,5500.0,24,29\\n', '24,1,10,1,0,1,2,3,0,112.0,199.2,1.0,55.4,0.8638479441427463,5,1,0.9169811320754717,6,3.8,3.35,8.0,0.6355140186915887,4500.0,14,16\\n', '25,1,20,1,0,1,3,3,0,94.5,168.7,0.3162393162393164,52.6,0.31497284716834756,1,3,0.13962264150943396,6,3.24,3.08,9.4,0.29906542056074764,6600.0,26,29\\n', '26,1,20,1,0,1,3,2,0,95.7,158.7,0.2820512820512823,54.5,0.21411947245927077,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,31,38\\n', '27,-1,5,1,0,0,5,2,0,103.3,174.6,0.3675213675213672,59.8,0.4061287820015516,3,3,0.23018867924528302,2,3.34,3.46,8.5,0.18691588785046728,5000.0,24,30\\n', '28,1,15,1,0,1,3,2,0,93.7,157.3,0.2991452991452991,50.8,0.16679596586501164,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,37,41\\n', '29,2,17,1,0,1,3,2,0,96.1,176.8,0.5384615384615381,50.5,0.3770364623739333,3,3,0.2679245283018868,6,3.46,3.9,8.7,0.09345794392523364,5500.0,23,31\\n', '30,-1,22,1,0,0,4,3,0,109.1,188.8,0.7350427350427355,55.5,0.591155934833204,5,4,0.4226415094339623,6,3.58,2.87,8.8,0.40186915887850466,5500.0,18,23\\n', '31,2,21,0,0,1,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.29984484096198605,3,3,0.13584905660377358,4,3.01,3.4,23.0,0.018691588785046728,4800.0,37,46\\n', '32,0,6,1,0,0,4,2,0,96.5,175.4,0.4188034188034192,54.1,0.3165244375484872,3,3,0.18490566037735848,1,3.15,3.58,9.0,0.17757009345794392,5800.0,27,33\\n', '33,0,20,1,0,0,4,2,0,95.7,166.3,0.35042735042735107,53.0,0.2300232738557021,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,30,37\\n', '34,2,21,0,1,0,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.32234290147401085,3,3,0.13584905660377358,4,3.01,3.4,23.0,0.09345794392523364,4500.0,37,42\\n', '35,3,21,1,0,1,1,2,0,94.5,159.3,0.33333333333333376,55.6,0.29712955779674166,3,3,0.1811320754716981,6,3.19,3.4,8.5,0.19626168224299065,5500.0,24,29\\n', '36,0,19,1,0,0,4,2,0,97.2,172.0,0.4358974358974365,52.5,0.330488750969744,4,3,0.17735849056603772,6,3.62,2.64,9.0,0.21495327102803738,5200.0,26,32\\n', '37,2,19,1,0,1,3,2,0,93.7,157.9,0.2820512820512823,53.7,0.2451512800620636,4,3,0.17735849056603772,2,3.62,2.64,8.7,0.11682242990654206,4400.0,26,31\\n', '38,1,5,1,1,1,3,2,0,93.7,157.3,0.2991452991452991,50.8,0.2482544608223429,3,3,0.13962264150943396,6,3.03,3.39,7.6,0.2523364485981308,5500.0,24,30\\n', '39,0,19,1,0,0,4,2,0,97.2,172.0,0.4358974358974365,52.5,0.27230411171450736,4,3,0.17735849056603772,2,3.62,2.64,9.5,0.1588785046728972,4400.0,28,33\\n', '40,1,15,1,1,1,3,2,0,93.7,157.3,0.2991452991452991,50.8,0.2482544608223429,3,3,0.13962264150943396,7,3.03,3.39,7.6,0.2523364485981308,5500.0,24,30\\n', '41,0,9,1,0,0,4,2,0,98.8,177.8,0.52991452991453,55.5,0.35764158262218776,3,3,0.23018867924528302,2,3.39,3.39,8.6,0.16822429906542055,4800.0,26,32\\n', '42,2,21,0,0,0,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.30100853374709075,3,3,0.13584905660377358,4,3.01,3.4,23.0,0.018691588785046728,4800.0,37,46\\n', '43,1,20,1,0,1,4,3,0,94.5,168.7,0.3162393162393164,52.6,0.26415826221877425,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,29,34\\n', '44,3,13,1,0,1,3,3,0,91.3,170.7,0.6495726495726502,49.7,0.6140418929402638,5,4,0.4528301886792453,6,3.43,3.27,9.0,0.5233644859813084,5200.0,19,25\\n', '45,0,20,1,0,0,4,2,0,95.7,166.3,0.35042735042735107,52.8,0.2529092319627618,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,28,34\\n', '46,1,15,1,0,0,3,2,0,93.7,157.3,0.2991452991452991,50.6,0.18580294802172226,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '47,1,4,1,0,1,3,2,0,94.5,155.9,0.2820512820512823,52.0,0.14972847168347556,3,3,0.10943396226415095,2,3.03,3.11,9.6,0.102803738317757,5400.0,38,43\\n', '48,1,13,1,0,0,5,2,0,94.5,170.2,0.2991452991452991,53.5,0.20791311093871218,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '49,1,13,0,0,1,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.20519782777346782,3,3,0.15849056603773584,4,2.99,3.47,21.9,0.03271028037383177,4800.0,45,50\\n', '50,0,13,1,0,0,4,2,0,97.2,173.4,0.4188034188034192,54.7,0.3157486423584174,3,3,0.22264150943396227,2,3.33,3.47,8.5,0.22897196261682243,5200.0,27,34\\n', '51,0,3,1,0,0,4,3,0,101.2,176.8,0.3846153846153845,54.3,0.3518231186966641,3,3,0.17735849056603772,6,3.5,2.8,8.8,0.24766355140186916,5800.0,23,29\\n', '52,2,18,1,0,0,4,2,0,99.1,186.6,0.52991452991453,56.1,0.4681923972071373,3,3,0.22641509433962265,6,3.54,3.07,9.3,0.2897196261682243,5250.0,21,28\\n', '53,3,18,1,0,1,3,2,0,99.1,186.6,0.52991452991453,56.1,0.47284716834755625,3,3,0.22641509433962265,6,2.54,2.07,9.3,0.2897196261682243,5250.0,21,28\\n', '54,0,19,1,0,0,4,1,0,97.0,172.0,0.4358974358974365,54.3,0.34794414274631497,4,3,0.17735849056603772,2,3.62,2.64,9.0,0.1588785046728972,4800.0,24,25\\n', '55,0,20,0,0,0,4,2,0,95.7,166.3,0.35042735042735107,53.0,0.30527540729247477,3,3,0.18490566037735848,4,3.27,3.35,22.5,0.037383177570093455,4500.0,34,36\\n', '56,3,1,1,0,1,1,3,0,88.6,168.8,0.32478632478632447,48.8,0.41117145073700545,1,3,0.26037735849056604,6,3.47,2.68,9.0,0.29439252336448596,5000.0,21,27\\n', '57,0,19,1,1,0,5,1,0,96.9,173.6,0.4358974358974365,54.9,0.45073700543056633,4,3,0.17735849056603772,6,3.62,2.64,7.7,0.29439252336448596,4800.0,23,23\\n', '58,3,20,1,0,1,3,3,0,102.9,183.5,0.6324786324786328,52.0,0.5771916214119472,1,4,0.41509433962264153,6,3.27,3.35,9.3,0.5280373831775701,5200.0,20,24\\n', '59,2,6,1,0,1,3,2,0,86.6,144.6,0.30769230769230776,50.8,0.12839410395655548,3,3,0.1169811320754717,1,2.91,3.41,9.2,0.1308411214953271,6000.0,31,38\\n', '60,1,9,1,0,1,3,2,0,98.8,177.8,0.52991452991453,53.7,0.34794414274631497,3,3,0.23018867924528302,2,3.39,3.39,8.6,0.16822429906542055,4800.0,26,32\\n', '61,-2,22,1,0,0,4,3,0,104.3,188.8,0.5897435897435901,56.2,0.5612878200155159,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,24,28\\n', '62,1,2,1,0,0,5,2,0,105.8,192.7,0.9487179487179492,55.7,0.5686578743211792,3,2,0.2830188679245283,6,3.19,3.4,8.5,0.2897196261682243,5500.0,19,25\\n', '63,-1,20,1,0,0,4,2,0,102.4,175.6,0.52991452991453,54.9,0.3591931730023274,3,3,0.23018867924528302,6,3.31,3.54,8.7,0.205607476635514,4200.0,27,32\\n', '64,1,13,1,0,1,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.1795965865011637,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '65,-1,22,1,1,0,4,3,0,109.1,188.8,0.7350427350427355,55.5,0.6105508145849495,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,19,25\\n', '66,2,7,1,0,1,3,3,0,96.0,172.6,0.4188034188034192,51.4,0.48332040341349886,3,3,0.2188679245283019,8,3.43,3.23,9.2,0.19626168224299065,5000.0,24,29\\n', '67,0,19,1,0,0,4,2,0,97.2,172.0,0.4358974358974365,52.5,0.2548487199379364,4,3,0.17735849056603772,2,3.62,2.64,9.5,0.1588785046728972,4800.0,32,37\\n', '68,0,6,1,0,0,5,2,0,96.5,157.1,0.30769230769230776,58.3,0.20791311093871218,3,3,0.1169811320754717,1,2.92,3.41,9.2,0.1308411214953271,6000.0,30,34\\n', '69,2,20,1,0,1,3,3,0,98.4,176.2,0.45299145299145266,52.0,0.41233514352211015,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '70,0,21,1,0,0,4,2,0,100.4,180.2,0.5641025641025647,55.1,0.45500387897595035,3,2,0.2830188679245283,6,3.19,3.4,8.5,0.2897196261682243,5500.0,19,24\\n', '71,1,6,1,0,1,3,2,0,93.7,150.0,0.3162393162393164,52.6,0.17532971295577968,3,3,0.1169811320754717,1,2.91,3.41,9.2,0.1308411214953271,6000.0,30,34\\n', '72,3,16,1,0,1,1,3,1,89.5,168.9,0.40170940170940184,51.6,0.5089216446858029,4,4,0.5018867924528302,6,3.74,2.9,9.5,0.7429906542056075,5900.0,17,25\\n', '73,0,6,1,0,1,3,2,0,96.5,167.5,0.4188034188034192,53.3,0.31070597362296354,3,3,0.18490566037735848,1,3.15,3.58,9.0,0.17757009345794392,5800.0,27,33\\n', '74,1,2,1,0,0,4,2,0,105.8,192.7,0.9487179487179492,55.7,0.525989138867339,3,2,0.2830188679245283,6,3.19,3.4,8.5,0.2897196261682243,5500.0,19,25\\n', '75,2,21,1,0,0,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.2808378588052754,3,3,0.1811320754716981,6,3.19,3.4,9.0,0.17289719626168223,5250.0,27,34\\n', '76,0,3,1,0,0,4,3,0,101.2,176.8,0.3846153846153845,54.3,0.49534522885958104,3,4,0.3886792452830189,6,3.31,3.19,9.0,0.3411214953271028,4250.0,21,28\\n', '77,2,12,1,0,1,3,2,0,93.7,157.3,0.35042735042735107,50.8,0.1768813033359193,3,3,0.1169811320754717,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '78,0,7,1,0,0,4,2,0,94.5,155.9,0.2820512820512823,52.0,0.16330488750969743,3,3,0.10943396226415095,2,3.03,3.11,9.6,0.102803738317757,5400.0,38,43\\n', '79,1,6,1,0,1,3,2,0,93.7,150.0,0.3162393162393164,52.6,0.13537626066718386,3,3,0.06792452830188679,1,2.91,3.07,10.1,0.056074766355140186,5500.0,38,42\\n', '80,1,5,1,0,0,3,2,0,93.7,157.3,0.2991452991452991,50.6,0.18580294802172226,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '81,2,21,1,0,1,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.2796741660201707,3,3,0.1811320754716981,6,3.19,3.4,9.0,0.17289719626168223,5250.0,27,34\\n', '82,1,13,1,0,1,3,2,0,94.5,165.6,0.2991452991452991,53.3,0.20946470131885184,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '83,0,19,1,0,0,5,1,0,96.9,173.6,0.4358974358974365,54.9,0.36152055857253684,4,3,0.17735849056603772,2,3.62,2.64,9.0,0.1588785046728972,4800.0,23,29\\n', '84,0,21,1,0,0,5,2,0,100.4,183.1,0.5641025641025647,55.1,0.4169899146625291,3,3,0.1811320754716981,6,3.19,3.4,9.0,0.18691588785046728,5500.0,25,31\\n', '85,-1,22,1,0,0,5,3,0,104.3,188.8,0.5897435897435901,57.5,0.6027928626842514,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,24,28\\n', '86,1,9,1,0,0,4,2,0,93.1,166.8,0.33333333333333376,54.1,0.17726920093095422,3,3,0.11320754716981132,2,3.03,3.15,9.0,0.09345794392523364,5000.0,31,38\\n', '87,0,14,1,0,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.6155934833204034,2,3,0.22264150943396227,6,3.46,2.19,8.4,0.21962616822429906,5000.0,19,24\\n', '88,2,21,1,0,0,4,2,0,97.3,171.7,0.4444444444444446,55.7,0.31497284716834756,3,3,0.1811320754716981,6,3.19,3.4,10.0,0.24299065420560748,5500.0,26,32\\n', '89,3,12,1,0,1,3,2,0,96.3,173.0,0.4358974358974365,49.4,0.32583397982932505,3,3,0.23018867924528302,2,3.35,3.46,8.5,0.18691588785046728,5000.0,25,32\\n', '90,2,12,1,0,1,3,2,0,93.7,157.3,0.35042735042735107,50.8,0.16679596586501164,3,3,0.1169811320754717,2,2.97,3.23,9.4,0.09345794392523364,5500.0,37,41\\n', '91,-1,20,1,0,0,5,3,0,104.5,187.8,0.52991452991453,54.1,0.6450737005430567,1,4,0.37735849056603776,6,3.27,3.35,9.2,0.5046728971962616,5200.0,19,24\\n', '92,-1,22,1,1,0,5,3,0,104.3,188.8,0.5897435897435901,57.5,0.6474010861132661,3,3,0.26037735849056604,6,3.62,3.15,7.5,0.5327102803738317,5100.0,17,22\\n', '93,0,9,0,0,0,4,2,0,98.8,177.8,0.52991452991453,55.5,0.3704422032583398,3,3,0.23018867924528302,4,3.39,3.39,22.7,0.07476635514018691,4650.0,36,42\\n', '94,1,11,1,1,1,3,3,0,102.7,178.4,0.6581196581196582,54.8,0.5515903801396431,3,3,0.2981132075471698,6,3.78,3.12,8.0,0.5934579439252337,5000.0,19,24\\n', '95,2,19,1,0,1,3,1,0,93.3,157.3,0.2991452991452991,55.7,0.2916989914662529,4,3,0.17735849056603772,2,3.62,2.64,8.7,0.11682242990654206,4400.0,26,31\\n', '96,3,16,1,0,1,2,3,1,89.5,168.9,0.40170940170940184,51.6,0.4918541505042669,4,4,0.5018867924528302,6,3.74,2.9,9.5,0.7429906542056075,5900.0,17,25\\n', '97,-1,10,0,1,0,4,3,0,115.6,202.6,0.9743589743589746,56.3,0.8851823118696664,3,2,0.46037735849056605,4,3.58,3.64,21.5,0.35046728971962615,4350.0,22,25\\n', '98,0,14,1,0,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.5942591155934833,2,3,0.22264150943396227,6,3.46,3.19,8.4,0.22897196261682243,5000.0,19,24\\n', '99,-1,15,1,0,0,5,2,0,103.3,174.6,0.3675213675213672,59.8,0.4061287820015516,3,3,0.23018867924528302,2,3.35,3.46,8.5,0.18691588785046728,5000.0,24,30\\n', '100,1,7,1,0,1,4,2,0,94.5,155.9,0.2820512820512823,52.0,0.14972847168347556,3,3,0.10943396226415095,2,3.03,3.11,9.6,0.102803738317757,5400.0,38,43\\n', '101,3,5,1,1,1,3,2,0,95.9,173.2,0.5128205128205127,50.2,0.5131885182311869,3,3,0.3584905660377358,5,3.6,3.9,7.0,0.4532710280373832,5000.0,19,24\\n', '102,0,14,1,1,0,4,3,0,108.0,186.7,0.6837606837606836,56.0,0.6369278510473235,2,3,0.27547169811320754,6,3.61,3.21,7.0,0.4392523364485981,5600.0,18,24\\n', '103,1,20,1,0,1,4,3,0,94.5,168.7,0.3162393162393164,52.6,0.3013964313421257,1,3,0.13962264150943396,6,3.24,3.08,9.4,0.29906542056074764,6600.0,26,29\\n', '104,-2,22,1,0,0,4,3,0,104.3,188.8,0.5897435897435901,56.2,0.552366175329713,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,23,28\\n', '105,1,9,1,0,0,4,2,0,93.1,166.8,0.33333333333333376,54.1,0.1792086889061288,3,3,0.11320754716981132,2,3.08,3.15,9.0,0.09345794392523364,5000.0,31,38\\n', '106,1,12,1,1,1,3,2,0,93.0,157.3,0.2991452991452991,50.8,0.2548487199379364,3,3,0.13962264150943396,7,3.03,3.39,7.6,0.2523364485981308,5500.0,24,30\\n', '107,2,13,1,0,1,2,2,0,95.1,162.4,0.2991452991452991,53.3,0.2017067494181536,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '108,1,1,1,0,1,3,3,0,94.5,171.2,0.4444444444444446,52.4,0.5178432893716058,5,4,0.3433962264150943,6,2.68,3.47,9.0,0.4953271028037383,5000.0,19,26\\n', '109,0,6,1,0,1,3,2,0,96.5,167.5,0.4188034188034192,53.3,0.29014740108611325,3,3,0.18490566037735848,1,3.15,3.58,9.0,0.17757009345794392,5800.0,27,33\\n', '110,2,2,1,0,0,4,2,0,99.8,176.6,0.5042735042735046,54.3,0.32932505818463925,3,3,0.1811320754716981,6,3.19,3.4,10.0,0.2523364485981308,5500.0,24,30\\n', '111,-1,20,1,0,0,4,3,0,104.5,187.8,0.52991452991453,54.1,0.6373157486423584,1,4,0.41509433962264153,6,3.27,3.35,9.2,0.5046728971962616,5200.0,20,24\\n', '112,1,12,1,0,0,4,2,0,96.3,172.4,0.4358974358974365,51.6,0.3557020946470132,3,3,0.23018867924528302,2,3.35,3.46,8.5,0.18691588785046728,5000.0,25,32\\n', '113,0,20,0,0,0,3,2,0,95.7,166.3,0.35042735042735107,52.8,0.30527540729247477,3,3,0.18490566037735848,4,3.27,3.35,22.5,0.037383177570093455,4500.0,38,47\\n', '114,1,13,1,0,0,5,2,0,94.5,170.2,0.2991452991452991,53.5,0.212955779674166,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '115,0,4,1,0,0,4,2,0,94.5,158.8,0.2820512820512823,52.0,0.16330488750969743,3,3,0.10943396226415095,2,3.03,3.11,9.6,0.102803738317757,5400.0,38,43\\n', '116,1,12,1,1,0,4,2,0,96.3,172.4,0.4358974358974365,51.6,0.3549262994569434,3,3,0.18490566037735848,7,3.17,3.46,7.5,0.3177570093457944,5500.0,23,30\\n', '117,0,6,1,0,0,4,2,0,96.5,163.4,0.3162393162393164,54.5,0.20248254460822343,3,3,0.1169811320754717,1,2.91,3.41,9.2,0.1308411214953271,6000.0,30,34\\n', '118,2,3,1,0,1,4,3,0,101.2,176.8,0.3846153846153845,54.3,0.3518231186966641,3,3,0.17735849056603772,6,3.5,2.8,8.8,0.24766355140186916,5800.0,23,29\\n', '119,0,8,1,0,0,4,3,0,113.0,199.6,0.7948717948717945,52.8,1.0,1,4,0.7433962264150943,6,3.63,4.17,8.1,0.5981308411214953,4750.0,15,19\\n', '120,3,9,1,0,1,3,3,0,95.3,169.0,0.4615384615384619,49.6,0.3460046547711404,6,7,0.033962264150943396,3,3.62,3.4,9.4,0.24766355140186916,6000.0,17,23\\n', '121,0,14,1,0,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.6155934833204034,2,3,0.22264150943396227,6,3.46,3.19,8.4,0.22897196261682243,5000.0,19,24\\n', '122,3,12,1,1,1,3,2,0,95.9,173.2,0.5128205128205127,50.2,0.5577967416602017,3,3,0.3584905660377358,7,3.59,3.86,7.0,0.4532710280373832,5000.0,19,24\\n', '123,3,9,1,0,1,3,3,0,95.3,169.0,0.4615384615384619,49.6,0.34794414274631497,6,7,0.033962264150943396,3,3.62,3.4,9.4,0.24766355140186916,6000.0,17,23\\n', '124,0,2,1,1,1,3,1,0,99.5,178.2,0.6495726495726502,52.0,0.6070597362296354,3,2,0.2641509433962264,6,3.13,3.4,7.0,0.5233644859813084,5500.0,16,22\\n', '125,0,20,1,0,0,3,2,0,95.7,166.3,0.35042735042735107,52.8,0.24088440651667958,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,30,37\\n', '126,1,20,1,0,0,3,2,0,95.7,158.7,0.2820512820512823,54.5,0.20442203258339797,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,31,38\\n', '127,3,9,1,0,1,3,3,0,95.3,169.0,0.4615384615384619,49.6,0.3460046547711404,6,7,0.033962264150943396,3,3.62,3.4,9.4,0.24766355140186916,6000.0,17,23\\n', '128,1,5,1,0,1,3,2,0,93.7,157.3,0.2991452991452991,50.8,0.15050426687354537,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '129,1,9,1,0,1,3,2,0,98.8,177.8,0.52991452991453,53.7,0.34794414274631497,3,3,0.23018867924528302,2,3.39,3.39,8.6,0.16822429906542055,4800.0,26,32\\n', '130,2,20,1,0,1,3,3,0,98.4,176.2,0.45299145299145266,52.0,0.47556245151280063,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '131,0,14,0,1,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.6629169899146625,2,3,0.3433962264150943,4,3.7,3.52,21.0,0.21962616822429906,4150.0,28,33\\n', '132,0,19,1,0,0,5,2,0,97.0,173.5,0.4358974358974365,53.0,0.3750969743987587,4,3,0.17735849056603772,6,3.62,2.64,9.0,0.21495327102803738,5200.0,25,31\\n', '133,0,10,0,1,1,2,3,0,106.7,187.5,0.8547008547008544,54.9,0.778510473235066,3,2,0.46037735849056605,4,3.58,3.64,21.5,0.35046728971962615,4350.0,22,25\\n', '134,0,13,1,0,0,4,2,0,100.4,184.6,0.52991452991453,55.1,0.6097750193948798,5,4,0.4528301886792453,6,3.43,3.27,9.0,0.48598130841121495,5200.0,19,25\\n', '135,-2,22,1,1,0,4,3,0,104.3,188.8,0.5897435897435901,56.2,0.6039565554693561,3,3,0.26037735849056604,6,3.62,3.15,7.5,0.5327102803738317,5100.0,17,22\\n', '136,1,20,1,0,1,3,3,0,94.5,168.7,0.3162393162393164,52.6,0.27773467804499613,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,29,34\\n', '137,0,10,1,0,0,4,3,0,120.9,208.1,0.9743589743589746,56.7,0.9356089992242048,5,1,0.9320754716981132,6,3.8,3.35,8.0,0.6355140186915887,4500.0,14,16\\n', '138,3,12,1,1,1,3,2,0,96.3,173.0,0.4358974358974365,49.4,0.3421256788207913,3,3,0.18490566037735848,7,3.17,3.46,7.5,0.3177570093457944,5500.0,23,30\\n', '139,1,13,1,0,0,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.17455391776570986,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '140,-1,10,1,0,0,4,3,0,115.6,202.6,0.9743589743589746,56.5,0.873545384018619,5,1,0.6528301886792452,6,3.46,3.1,8.3,0.5,4750.0,16,18\\n', '141,0,13,1,0,0,3,2,0,97.2,173.4,0.4188034188034192,54.7,0.3242823894491854,3,3,0.22264150943396227,2,3.33,3.47,8.5,0.22897196261682243,5200.0,27,34\\n', '142,1,5,1,0,1,3,2,0,93.7,157.3,0.2991452991452991,50.8,0.15050426687354537,3,3,0.10943396226415095,2,2.97,3.23,9.41,0.09345794392523364,5500.0,37,41\\n', '143,-1,22,1,0,0,5,3,0,104.3,188.8,0.5897435897435901,57.5,0.5996896819239721,3,3,0.3018867924528302,6,3.78,3.15,9.5,0.308411214953271,5400.0,23,28\\n', '144,3,10,1,0,1,1,3,0,96.6,180.3,0.8717948717948718,50.8,0.852211016291699,5,1,0.6528301886792452,6,3.46,3.1,8.3,0.5,4750.0,16,18\\n', '145,0,9,1,0,0,4,3,0,104.9,175.0,0.49572649572649535,54.4,0.45849495733126455,3,3,0.2981132075471698,6,3.76,3.16,8.0,0.3364485981308411,5000.0,19,27\\n', '146,0,9,1,0,0,4,2,0,98.8,177.8,0.52991452991453,55.5,0.35764158262218776,3,3,0.23018867924528302,2,3.39,3.39,8.6,0.16822429906542055,4800.0,26,32\\n', '147,1,2,1,1,0,4,2,0,105.8,192.7,0.9487179487179492,55.9,0.6198603568657874,3,2,0.2641509433962264,6,3.13,3.4,8.3,0.42990654205607476,5500.0,17,20\\n', '148,1,5,1,0,0,4,2,0,93.7,157.3,0.2991452991452991,50.6,0.1943366951124903,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '149,0,9,1,0,0,3,2,0,98.8,177.8,0.52991452991453,55.5,0.3634600465477114,3,3,0.23018867924528302,2,3.39,3.39,8.6,0.16822429906542055,4800.0,26,32\\n', '150,1,6,1,0,1,4,2,0,96.5,169.1,0.4871794871794873,51.0,0.31225756400310317,3,3,0.18490566037735848,2,3.15,3.58,9.1,0.24299065420560748,5500.0,25,31\\n', '151,0,8,1,0,0,4,3,0,113.0,199.6,0.7948717948717945,52.8,1.0,1,4,0.7433962264150943,6,3.63,4.17,8.1,0.5981308411214953,4750.0,15,19\\n', '152,3,18,1,1,1,3,2,0,99.1,186.6,0.52991452991453,56.1,0.5120248254460822,1,3,0.22641509433962265,6,3.54,3.07,9.0,0.5233644859813084,5500.0,19,26\\n', '153,0,6,1,0,0,4,2,0,96.5,175.4,0.18803418803418823,54.1,0.34290147401086113,3,3,0.18490566037735848,1,3.15,3.58,9.0,0.17757009345794392,5800.0,27,33\\n', '154,0,20,1,0,0,5,1,0,95.7,169.7,0.2820512820512823,59.1,0.3110938712179985,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,27,32\\n', '155,0,20,1,0,0,3,2,0,95.7,166.3,0.35042735042735107,52.8,0.24592707525213345,3,3,0.13962264150943396,2,3.19,3.03,9.0,0.102803738317757,4800.0,28,34\\n', '156,3,9,1,0,1,3,3,0,95.3,169.0,0.4615384615384619,49.6,0.39255236617532974,6,7,0.07169811320754717,6,3.62,3.4,9.4,0.40654205607476634,6000.0,16,23\\n', '157,1,9,1,0,1,3,2,0,93.1,159.1,0.33333333333333376,54.1,0.15981380915438323,3,3,0.11320754716981132,2,3.03,3.15,9.0,0.09345794392523364,5000.0,31,38\\n', '158,2,2,1,0,0,4,1,0,99.4,176.6,0.521367521367522,54.3,0.5182311869666408,3,2,0.2830188679245283,6,3.19,3.4,8.0,0.3130841121495327,5500.0,18,22\\n', '159,0,14,0,1,0,5,3,0,114.2,198.9,0.6923076923076928,58.7,0.7746314972847168,2,3,0.3433962264150943,4,3.7,3.52,21.0,0.21962616822429906,4150.0,25,25\\n', '160,0,6,1,0,0,4,2,0,96.5,175.4,0.4188034188034192,54.1,0.37897595034910786,3,3,0.18490566037735848,6,3.15,3.58,9.0,0.24766355140186916,5800.0,24,28\\n', '161,3,16,1,0,1,3,3,0,94.5,168.9,0.6837606837606836,50.2,0.5003878975950349,3,3,0.33962264150943394,6,3.94,3.11,9.5,0.4439252336448598,5500.0,19,27\\n', '162,-1,20,1,0,0,3,2,0,102.4,175.6,0.52991452991453,53.9,0.3762606671838635,3,3,0.23018867924528302,6,3.31,3.54,8.7,0.205607476635514,4200.0,27,32\\n', '163,3,18,1,0,1,3,2,0,99.1,186.6,0.52991452991453,56.1,0.4538401861908456,3,3,0.22641509433962265,6,3.54,3.07,9.31,0.2897196261682243,5250.0,21,28\\n', '164,0,14,0,1,0,4,3,0,107.9,186.7,0.6923076923076928,56.7,0.6842513576415826,2,3,0.3433962264150943,4,3.7,3.52,21.0,0.21962616822429906,4150.0,28,33\\n', '165,1,20,1,0,1,3,2,0,95.7,158.7,0.2820512820512823,54.5,0.19278510473235067,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,35,39\\n', '166,0,14,1,0,0,5,3,0,114.2,198.9,0.6923076923076928,56.7,0.6970519782777347,2,3,0.22264150943396227,6,3.46,2.19,8.4,0.21962616822429906,5000.0,19,24\\n', '167,1,9,1,0,1,3,2,0,93.1,159.1,0.33333333333333376,54.1,0.15593483320403415,3,3,0.11320754716981132,2,3.03,3.15,9.0,0.09345794392523364,5000.0,30,31\\n', '168,0,14,1,0,0,5,3,0,114.2,198.9,0.6923076923076928,58.7,0.6757176105508146,2,3,0.22264150943396227,6,3.46,3.19,8.4,0.22897196261682243,5000.0,19,24\\n', '169,2,6,1,0,1,3,2,0,86.6,144.6,0.30769230769230776,50.8,0.08727695888285493,3,3,0.1169811320754717,1,2.91,3.41,9.6,0.04672897196261682,4800.0,49,54\\n', '170,2,2,1,0,1,4,2,0,99.8,177.3,0.5128205128205127,53.1,0.39526764934057407,3,2,0.2830188679245283,6,3.19,3.4,8.5,0.2897196261682243,5500.0,19,25\\n', '171,3,12,1,1,1,3,2,0,95.9,173.2,0.5128205128205127,50.2,0.5558572536850271,3,3,0.3584905660377358,7,3.59,3.86,7.0,0.4532710280373832,5000.0,19,24\\n', '172,3,12,1,1,1,3,2,0,95.9,173.2,0.5128205128205127,50.2,0.521722265321955,3,3,0.3584905660377358,7,3.58,3.86,7.0,0.4532710280373832,5000.0,19,24\\n', '173,2,18,1,1,0,4,2,0,99.1,186.6,0.52991452991453,56.1,0.5271528316524438,1,3,0.22641509433962265,6,3.54,3.07,9.0,0.5233644859813084,5500.0,19,26\\n', '174,-1,20,1,0,0,3,2,0,102.4,175.6,0.52991452991453,53.9,0.3591931730023274,3,3,0.23018867924528302,6,3.31,3.54,8.7,0.205607476635514,4200.0,27,32\\n', '175,1,9,1,0,1,3,2,0,93.1,159.1,0.33333333333333376,54.1,0.1617532971295578,3,3,0.11320754716981132,2,3.03,3.15,9.0,0.09345794392523364,5000.0,31,38\\n', '176,3,16,1,0,1,2,3,1,89.5,168.9,0.40170940170940184,51.6,0.4918541505042669,4,4,0.5018867924528302,6,3.74,2.9,9.5,0.7429906542056075,5900.0,17,25\\n', '177,1,13,1,0,1,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.15554693560899924,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '178,0,13,1,0,0,4,2,0,100.4,181.7,0.52991452991453,55.1,0.6233514352211016,5,4,0.4528301886792453,6,3.43,3.27,9.0,0.48598130841121495,5200.0,17,22\\n', '179,1,13,1,0,0,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.18735453840186192,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '180,0,20,1,0,0,5,1,0,95.7,169.7,0.2820512820512823,59.1,0.6291698991466252,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,27,32\\n', '181,1,5,1,0,0,4,2,0,93.7,157.3,0.2991452991452991,50.6,0.1943366951124903,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '182,0,21,0,1,0,4,2,0,100.4,180.2,0.5641025641025647,55.1,0.42319627618308764,3,3,0.13584905660377358,4,3.01,3.4,23.0,0.09345794392523364,4500.0,33,38\\n', '183,1,12,1,0,0,4,2,0,96.3,172.4,0.4358974358974365,51.6,0.34018619084561674,3,3,0.23018867924528302,2,3.35,3.46,8.5,0.18691588785046728,5000.0,25,32\\n', '184,2,20,1,0,1,1,3,0,98.4,176.2,0.45299145299145266,53.0,0.5768037238169124,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '185,-1,20,1,0,0,4,2,0,102.4,175.6,0.52991452991453,54.9,0.32505818463925523,3,3,0.23018867924528302,6,3.31,3.54,8.7,0.205607476635514,4200.0,29,34\\n', '186,0,3,1,0,0,4,3,0,103.5,189.0,0.5641025641025647,55.7,0.6757176105508146,3,4,0.5584905660377358,6,3.62,3.39,8.0,0.6261682242990654,5400.0,16,22\\n', '187,2,4,1,0,1,3,2,0,88.4,141.1,0.0,53.2,0.0,2,5,0.0,2,2.91,3.03,9.5,0.0,5100.0,47,53\\n', '188,-1,20,0,1,0,4,2,0,102.4,175.6,0.52991452991453,54.9,0.3847944142746315,3,3,0.18490566037735848,4,3.27,3.35,22.5,0.11682242990654206,4500.0,30,33\\n', '189,1,15,1,0,0,4,2,0,93.7,167.3,0.2991452991452991,50.8,0.1943366951124903,3,3,0.10943396226415095,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '190,0,19,1,1,0,4,1,0,97.0,172.0,0.4358974358974365,54.3,0.3964313421256788,4,3,0.17735849056603772,6,3.62,2.64,7.7,0.29439252336448596,4800.0,24,29\\n', '191,0,17,1,0,0,5,2,0,96.1,181.5,0.52991452991453,55.2,0.42319627618308764,3,3,0.2679245283018868,6,3.46,3.9,8.7,0.09345794392523364,5500.0,23,31\\n', '192,-1,12,1,0,0,4,2,0,96.3,172.4,0.4358974358974365,51.6,0.3549262994569434,3,3,0.18490566037735848,7,3.17,3.46,7.5,0.3177570093457944,5500.0,23,30\\n', '193,3,15,1,1,1,3,3,0,95.9,173.2,0.5128205128205127,50.2,0.5159038013964313,3,3,0.3584905660377358,7,3.59,3.86,7.0,0.4532710280373832,5000.0,19,24\\n', '194,0,20,1,0,0,5,2,0,95.7,169.7,0.2820512820512823,59.1,0.30721489526764933,3,3,0.1169811320754717,2,3.05,3.03,9.0,0.06542056074766354,4800.0,31,37\\n', '195,1,15,1,0,0,4,2,0,93.7,167.3,0.2991452991452991,50.8,0.2726920093095423,3,3,0.13962264150943396,2,2.97,3.23,9.4,0.09345794392523364,5500.0,31,38\\n', '196,1,3,1,0,0,4,3,0,103.5,189.0,0.5641025641025647,55.7,0.6078355314197051,3,4,0.3886792452830189,6,3.31,3.19,9.0,0.3411214953271028,4250.0,20,25\\n', '197,0,3,1,0,1,4,3,0,101.2,176.8,0.3846153846153845,54.3,0.474010861132661,3,4,0.3886792452830189,6,3.31,3.19,9.0,0.3411214953271028,4250.0,21,28\\n', '198,0,13,1,0,0,5,2,0,100.4,184.6,0.52991452991453,56.1,0.7013188518231187,5,4,0.4528301886792453,6,3.43,3.27,9.0,0.48598130841121495,5200.0,17,22\\n', '199,0,3,1,0,1,4,3,0,103.5,193.8,0.6495726495726502,53.7,0.7339022498060512,3,4,0.5584905660377358,6,3.62,3.39,8.0,0.6261682242990654,5400.0,16,22\\n', '200,1,13,1,0,1,4,2,0,94.5,165.3,0.2991452991452991,54.5,0.16679596586501164,3,3,0.13584905660377358,2,3.15,3.29,9.4,0.09813084112149532,5200.0,31,37\\n', '201,-1,22,1,1,0,4,3,0,109.1,188.8,0.7264957264957264,55.5,0.6055081458494957,3,3,0.3018867924528302,6,3.78,3.15,8.7,0.5233644859813084,5300.0,19,25\\n', '202,2,20,1,0,1,2,3,0,98.4,176.2,0.45299145299145266,52.0,0.4065166795965865,3,3,0.32075471698113206,6,3.62,3.5,9.3,0.3177570093457944,4800.0,24,30\\n', '203,0,7,1,0,0,4,3,0,94.3,170.7,0.12820512820512817,53.5,0.32932505818463925,3,3,0.18867924528301888,2,3.31,3.23,8.5,0.14018691588785046,4800.0,24,29\\n']\n"
     ]
    }
   ],
   "source": [
    "data = open(\"car.features\", 'r').readlines()\n",
    "labels = open(\"car.labels\", 'r').readlines()\n",
    "\n",
    "train_features = []\n",
    "train_labels   = []\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "\n",
    "\n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "\n",
    "instances = data[1:]\n",
    "\n",
    "print(instances)\n",
    "\n",
    "for instance in instances:\n",
    "    instance = instance.strip().split(\",\")\n",
    "    #print(instance)\n",
    "\n",
    "###########################\n",
    "## YOUR CODE ENDS HERE\n",
    "###########################\n",
    "\n",
    "# print(\"number of train/test instances:\",len(train_features), len(test_features))\n",
    "#print(\"number of train/test features:\",len(train_features[40]), len(test_features[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Distance Functions [1.5 marks]\n",
    "\n",
    "<b>Instructions</b>: Implement the three distance functions specified below. \n",
    "\n",
    "1. Euclidean distance\n",
    "2. Cosine distance\n",
    "3. Chebyshev distance, defined as:\n",
    "    \n",
    "    $d(x,y)=\\max_{i}|x_i-y_i|$\n",
    "    \n",
    "\n",
    "Each distance function takes as input\n",
    "- Two feature vectors (each of type List)\n",
    "\n",
    "and returns as output\n",
    "- The distance between the two feature vectors (float)\n",
    "\n",
    "------------\n",
    "\n",
    "Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def euclidean_distance(fw1, fw2):\n",
    "    # insert code here\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cosine_distance(fw1, fw2):\n",
    "    # insert code here\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "def chebyshev_distance(fw1, fw2):\n",
    "    # insert code here\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "## YOUR CODE ENDS HERE\n",
    "###########################\n",
    "\n",
    "print(round(euclidean_distance(train_features[100],test_features[2]), 5))\n",
    "print(round(chebyshev_distance(train_features[100],test_features[2]), 5))\n",
    "print(round(cosine_distance(train_features[100],test_features[2]), 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: KNN Classifier [2.0 marks]\n",
    "\n",
    "<b>Instructions</b>: Here, you implement your KNN classifier. It takes as input \n",
    "- training data features\n",
    "- training data labels\n",
    "- test data features\n",
    "- parameter K\n",
    "- distance function(s) based on which nearest neighbors will be identified\n",
    "\n",
    "It returns as output \n",
    "- the predicted labels for the test data\n",
    "\n",
    "**Ties among distances**. If there are more than K instances with the same (smallest) distance value, consider the first K. For example, for K=1 if you have 3 instances (with identifiers i = 3, 12, 54) that all have the same distance to your test instance (e.g., 0.641), the instance with the smallest identifier should be selected as the nearest neighbor (in this case i = 3).\n",
    "\n",
    "**Ties at prediction time.** Ties can also occur at class prediction time when two (or more) classes are supported by the same number of neighbors. In that case choose the class of the 1 nearest neighbor. The \"1 nearest neighbor\" refers only to those classes represented with the maximum support in the neighborhood. E.g., for K = 5, with a neighborhood ordered by distance: {'cheap', 'expensive', 'affordable', expensive', 'affordable'} you would choose the 1 nearest neighbor among {'expensive','affordable'}.\n",
    "\n",
    "-----------\n",
    "\n",
    "**You should implement the classifier from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library. You may use Python packages (e.g., math, numpy, collections, ...) to help with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(train_features, train_labels, test_features, k, dist_fun, weighted=False):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    ###########################\n",
    "    ## Your answer BEGINS HERE\n",
    "    ###########################\n",
    "    \n",
    "            \n",
    "            \n",
    "    ###########################\n",
    "    ## Your answer ENDS HERE\n",
    "    ###########################\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Weighted KNN Classifier [1.0 mark]\n",
    "\n",
    "<b>Instructions</b>: Extend your implementation of the KNN classifier in Question 3 to a Weighted KNN classifier. You should change the code in the cell above. Use Inverse Distance as weights:\n",
    "\n",
    "$w_j=\\frac{1}{d_j+\\epsilon}$\n",
    "\n",
    "where\n",
    "\n",
    "- $d_j$ is the distance of of the jth nearest neighbor to the test instance\n",
    "- $\\epsilon=0.000001$\n",
    "\n",
    "Use the Boolean parameter `weighted` to specify the KNN version when calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Applying your KNN classifiers to the Car Dataset [0.5 marks]\n",
    "\n",
    "**Using the functions you have implemented above, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "For each of the distance functions you implemented in Question 2, construct (a) Nine majority voting KNN classifiers and (b) Nine weighted KNN classifiers, respectively, with \n",
    "\n",
    "- K=1\n",
    "- K=5\n",
    "- k=20\n",
    "\n",
    "You will obtain a total of 18 (3 distance functions x 3 K values x 2 KNN versions) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model, where the accuracy is the fraction of correctly predicted labels over all predictions. Use the `accuracy_score` function from the `sklearn.metrics` package to obtain your accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "########################\n",
    "# Your code STARTS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy_knn_euc_1 = \n",
    "accuracy_knn_euc_5 = \n",
    "accuracy_knn_euc_20 = \n",
    " \n",
    "accuracy_knn_euc_1_w = \n",
    "accuracy_knn_euc_5_w = \n",
    "accuracy_knn_euc_20_w = \n",
    "\n",
    "accuracy_knn_cos_1 = \n",
    "accuracy_knn_cos_5 =  \n",
    "accuracy_knn_cos_20 = \n",
    "\n",
    "accuracy_knn_cos_1_w = \n",
    "accuracy_knn_cos_5_w =  \n",
    "accuracy_knn_cos_20_w = \n",
    "\n",
    "accuracy_knn_che_1 = \n",
    "accuracy_knn_che_5 = \n",
    "accuracy_knn_che_20 = \n",
    " \n",
    "accuracy_knn_che_1_w = \n",
    "accuracy_knn_che_5_w = \n",
    "accuracy_knn_che_20_w = \n",
    "\n",
    "########################\n",
    "# Your code ENDS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "print(\"Results on the *full* feature set\")\n",
    "\n",
    "print(\"\\neuclidean (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_euc_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_euc_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_euc_20, 3))\n",
    "\n",
    "print(\"-----------\\neuclidean (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_euc_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_euc_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_euc_20_w, 3))\n",
    "\n",
    "print(\"\\ncosine (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_cos_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_cos_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_cos_20, 3))\n",
    "\n",
    "print(\"-----------\\ncosine (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_cos_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_cos_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_cos_20_w, 3))\n",
    "\n",
    "print(\"\\nchebyshev (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_che_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_che_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_che_20, 3))\n",
    "\n",
    "print(\"-----------\\nchebyshev (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_che_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_che_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_che_20_w, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Analysis [4.5 marks]\n",
    "\n",
    "1. Consider the following features: make, fuel-type, body-style, and num-of-doors. Assume we intend to use KNN with euclidean distance, for each of the above features, would you change the approach we chose to convert nominal to numeric features? If yes, explain what approach you would select and discuss one benefit and one drawback of your proposed approach.**[0.75 marks]** \n",
    "\n",
    "    \n",
    "2. Consider these two sets of attributes: (curb-weight,engine-size) and (compression-ratio, peak-rpm)\n",
    "\n",
    "    (a) For each set of features, create a scatter plot of data points coloring instances from each class differently. You should produce **two plots** which show the scattered data points colored by class label. Label the x-axis and y-axis. [*N.B. you may use libraries like <a href=\"https://matplotlib.org/stable/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py\">matplotlib</a> or <a href=\"https://seaborn.pydata.org/introduction.html\">seaborne</a>*] **[1 mark]**\n",
    "    \n",
    "    (b) Which feature set is more informative in the context of this classification task and why?**[0.5 marks]**\n",
    "    \n",
    "    (c) What do you observe about the relationship between features in each feature set and how did you come to that conclusion?**[0.25 marks]**\n",
    "    \n",
    "    \n",
    "3. Discuss the appropriateness of each of the distance functions for our *car* data set. Where appropriate, explain why you expect them to perform poorly referring to both their mathematical properties and the given feature set. **[0.75 marks]**\n",
    "\n",
    "    \n",
    "\n",
    "4. Does the Weighted KNN outperform the Majority voting version, or vice versa? Hypothesize why (not). **[0.75 mark]**\n",
    "\n",
    "\n",
    "\n",
    "5. Do you think the accuracy is an appropriate evaluation metric for the *car* data set? Why (not)? **[0.5 marks]**\n",
    "\n",
    " \n",
    "\n",
    "<b>Each question should be answered in no more than 3-4 sentences.</b>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1\n",
    "\n",
    "2\n",
    "\n",
    "*Type code for 2.(a) in the cell below, and answer 2.(b) and 2.(c) below*\n",
    "\n",
    "2b)\n",
    "\n",
    "2c)\n",
    "\n",
    "3\n",
    "\n",
    "4\n",
    "\n",
    "5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################\n",
    "# Your answer to Question 6 (2) STARTS HERE\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Your answer to Question 6 (2) ENDS HERE\n",
    "################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Authorship Declaration</b>:\n",
    "\n",
    "   (1) I certify that the program contained in this submission is completely\n",
    "   my own individual work, except where explicitly noted by comments that\n",
    "   provide details otherwise.  I understand that work that has been developed\n",
    "   by another student, or by me in collaboration with other students,\n",
    "   or by non-students as a result of request, solicitation, or payment,\n",
    "   may not be submitted for assessment in this subject.  I understand that\n",
    "   submitting for assessment work developed by or in collaboration with\n",
    "   other students or non-students constitutes Academic Misconduct, and\n",
    "   may be penalized by mark deductions, or by other penalties determined\n",
    "   via the University of Melbourne Academic Honesty Policy, as described\n",
    "   at https://academicintegrity.unimelb.edu.au.\n",
    "\n",
    "   (2) I also certify that I have not provided a copy of this work in either\n",
    "   softcopy or hardcopy or any other form to any other student, and nor will\n",
    "   I do so until after the marks are released. I understand that providing\n",
    "   my work to other students, regardless of my intention or any undertakings\n",
    "   made to me by that other student, is also Academic Misconduct.\n",
    "\n",
    "   (3) I further understand that providing a copy of the assignment\n",
    "   specification to any form of code authoring or assignment tutoring\n",
    "   service, or drawing the attention of others to such services and code\n",
    "   that may have been made available via such a service, may be regarded\n",
    "   as Student General Misconduct (interfering with the teaching activities\n",
    "   of the University and/or inciting others to commit Academic Misconduct).\n",
    "   I understand that an allegation of Student General Misconduct may arise\n",
    "   regardless of whether or not I personally make use of such solutions\n",
    "   or sought benefit from such actions.\n",
    "\n",
    "   <b>Signed by</b>: [Enter your full name and student number here before submission]\n",
    "   \n",
    "   <b>Dated</b>: [Enter the date that you \"signed\" the declaration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
