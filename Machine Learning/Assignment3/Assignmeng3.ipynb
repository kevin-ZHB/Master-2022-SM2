{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful module\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using embedding files\n",
    "# Should be adjusted for different file path.\n",
    "train_file = \"dataset/dataset/train_embedding.csv\"\n",
    "dev_file = \"dataset/dataset/dev_embedding.csv\"\n",
    "\n",
    "\"\"\"\n",
    "Load data using tf-idf files\n",
    "\n",
    "train_file = \"dataset/dataset/train_embedding.csv\"\n",
    "dev_file = \"dataset/dataset/dev_embedding.csv\"\n",
    "\"\"\"\n",
    "\n",
    "identity  = [\"Christian\", \"Muslim\", \"Female\", \"Homosexual gay or lesbian\",\"Male\"]\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "dev_data = pd.read_csv(dev_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn classification with pre-defined K = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knn_clf = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using whole data set and predict on different identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data[\"Toxicity\"]\n",
    "train_feature = train_data.iloc[:,26:]\n",
    "\n",
    "dev_label = dev_data[\"Toxicity\"]\n",
    "dev_feature = dev_data.iloc[:,26:]\n",
    "\n",
    "Knn_clf.fit(train_feature, train_label)\n",
    "\n",
    "for i in identity:\n",
    "    \n",
    "    dev = dev_data.loc[dev_data[i] == 1 ]\n",
    "    dev_label = dev[\"Toxicity\"]\n",
    "    dev_feature = dev.iloc[:,26:]\n",
    "\n",
    "    predic = Knn_clf.predict(dev_feature)\n",
    "    proba = Knn_clf.predict_proba(dev_feature)\n",
    "\n",
    "    # common metrics results\n",
    "    print(\"\\n \" + i)\n",
    "    print(metrics.classification_report(dev_label, predic))\n",
    "    # AUC score results\n",
    "    auc = metrics.roc_auc_score(dev_label, proba[:, 1])\n",
    "    print(\"AUC socore: %f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using different subset of different identities and predict on the identity correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in identity:\n",
    "\n",
    "    train = train_data.loc[train_data[i] == 1]\n",
    "    train_label = train[\"Toxicity\"]\n",
    "    train_feature = train.iloc[:, 26:]\n",
    "\n",
    "    dev = dev_data.loc[dev_data[i] == 1]\n",
    "    dev_label = dev[\"Toxicity\"]\n",
    "    dev_feature = dev.iloc[:, 26:]\n",
    "\n",
    "    Knn_clf.fit(train_feature, train_label)\n",
    "\n",
    "    predic = Knn_clf.predict(dev_feature)\n",
    "    proba = Knn_clf.predict_proba(dev_feature)\n",
    "\n",
    "    # common metrics results\n",
    "    print(\"\\n \" + i)\n",
    "    print(metrics.classification_report(dev_label, predic))\n",
    "    # AUC score results\n",
    "    auc = metrics.roc_auc_score(dev_label, proba[:, 1])\n",
    "    print(\"\\nAUC socore: %f\" % auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron classification with hidder layer size (5,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_clf = MLPClassifier(hidden_layer_sizes=(5,2),activation='logistic', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using whole data set and predict on different identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data[\"Toxicity\"]\n",
    "train_feature = train_data.iloc[:,26:]\n",
    "\n",
    "dev_label = dev_data[\"Toxicity\"]\n",
    "dev_feature = dev_data.iloc[:,26:]\n",
    "\n",
    "\n",
    "MLP_clf.fit(train_feature, train_label)\n",
    "\n",
    "for i in identity:\n",
    "    \n",
    "    dev = dev_data.loc[dev_data[i] == 1 ]\n",
    "    dev_label = dev[\"Toxicity\"]\n",
    "    dev_feature = dev.iloc[:,26:]\n",
    "\n",
    "    predic = MLP_clf.predict(dev_feature)\n",
    "    proba = MLP_clf.predict_proba(dev_feature)\n",
    "    # common metrics results\n",
    "    print(\"\\n \" + i)\n",
    "    print(metrics.classification_report(dev_label, predic))\n",
    "    # AUC score results\n",
    "    auc = metrics.roc_auc_score(dev_label, proba[:, 1])\n",
    "    print(\"\\nAUC socore: %f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using different subset of different identities and predict on the identity correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in identity:\n",
    "    \n",
    "    train = train_data.loc[train_data[i] == 1 ]\n",
    "    train_label = train[\"Toxicity\"]\n",
    "    train_feature = train.iloc[:,26:]\n",
    "    \n",
    "    dev = dev_data.loc[dev_data[i] == 1 ]\n",
    "    dev_label = dev[\"Toxicity\"]\n",
    "    dev_feature = dev.iloc[:,26:]\n",
    "    \n",
    "    MLP_clf.fit(train_feature, train_label)\n",
    "    \n",
    "    predic = MLP_clf.predict(dev_feature)\n",
    "    proba = MLP_clf.predict_proba(dev_feature)\n",
    "    # common metrics results\n",
    "    print(\"\\n \" + i)\n",
    "    print(metrics.classification_report(dev_label, predic))\n",
    "    # AUC score results\n",
    "    auc = metrics.roc_auc_score(dev_label, proba[:, 1])\n",
    "    print(\"\\nAUC socore: %f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classification using Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data[\"Toxicity\"]\n",
    "train_feature = train_data.iloc[:,26:]\n",
    "\n",
    "dev_label = dev_data[\"Toxicity\"]\n",
    "dev_feature = dev_data.iloc[:,26:]\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy= 'most_frequent')\n",
    "dummy_clf.fit(train_feature, train_label)\n",
    "\n",
    "for i in identity:\n",
    "    \n",
    "    dev = dev_data.loc[dev_data[i] == 1 ]\n",
    "    dev_label = dev[\"Toxicity\"]\n",
    "    dev_feature = dev.iloc[:,26:]\n",
    "\n",
    "    predic = dummy_clf.predict(dev_feature)\n",
    "    proba = dummy_clf.predict_proba(dev_feature)\n",
    "    # common metrics results\n",
    "    print(\"\\n \" + i)\n",
    "    print(metrics.classification_report(dev_label, predic))\n",
    "    # AUC score results\n",
    "    auc = metrics.roc_auc_score(dev_label, proba[:, 1])\n",
    "    print(\"\\nAUC socore: %f\" % auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
